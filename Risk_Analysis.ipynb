{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NM_lDtKgdHk",
        "outputId": "e6d3a2e2-f2fd-40c4-9987-ceb623231bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-77e0984a33ec>:10: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/MyDrive/merged_dataset.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        High       0.55      0.57      0.56    130776\n",
            "         Low       0.93      0.98      0.95    167254\n",
            "      Medium       0.85      0.81      0.83    297394\n",
            "\n",
            "    accuracy                           0.80    595424\n",
            "   macro avg       0.78      0.79      0.78    595424\n",
            "weighted avg       0.81      0.80      0.80    595424\n",
            "\n",
            "Model training complete. Artifacts saved in 'risk_model' folder.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "\n",
        "# Load crash dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/merged_dataset.csv')\n",
        "# Drop rows with missing key values\n",
        "df = df.dropna(subset=[\n",
        "    'POSTED_SPEED_LIMIT', 'WEATHER_CONDITION', 'LIGHTING_CONDITION',\n",
        "    'ROADWAY_SURFACE_COND', 'DAMAGE', 'NUM_UNITS', 'CRASH_HOUR',\n",
        "    'FIRST_CRASH_TYPE', 'INJURIES_TOTAL'\n",
        "])\n",
        "\n",
        "# Parse DAMAGE to numeric\n",
        "def parse_damage(val):\n",
        "    if isinstance(val, str):\n",
        "        val = val.replace(',', '')\n",
        "        if 'OVER' in val:\n",
        "            return 2000\n",
        "        elif 'LESS' in val:\n",
        "            return 500\n",
        "        elif '-' in val:\n",
        "            parts = val.replace('$', '').split(' - ')\n",
        "            return (int(parts[0]) + int(parts[1])) / 2\n",
        "    return 1000  # fallback\n",
        "\n",
        "df['DAMAGE_VALUE'] = df['DAMAGE'].apply(parse_damage)\n",
        "\n",
        "# Create RISK_LEVEL label\n",
        "def assign_risk(row):\n",
        "    if row['INJURIES_TOTAL'] >= 1:\n",
        "        return 'High'\n",
        "    elif row['DAMAGE_VALUE'] >= 1500:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "df['RISK_LEVEL'] = df.apply(assign_risk, axis=1)\n",
        "\n",
        "# Select features and label\n",
        "features = [\n",
        "    'POSTED_SPEED_LIMIT', 'WEATHER_CONDITION', 'LIGHTING_CONDITION',\n",
        "    'ROADWAY_SURFACE_COND', 'DAMAGE_VALUE', 'NUM_UNITS', 'CRASH_HOUR',\n",
        "    'FIRST_CRASH_TYPE'\n",
        "]\n",
        "label = 'RISK_LEVEL'\n",
        "df = df[features + [label]]\n",
        "\n",
        "# Encode categorical features\n",
        "encoders = {}\n",
        "for col in ['WEATHER_CONDITION', 'LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND', 'FIRST_CRASH_TYPE']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# Encode target label\n",
        "target_encoder = LabelEncoder()\n",
        "df[label] = target_encoder.fit_transform(df[label])\n",
        "\n",
        "# Train-test split\n",
        "X = df[features]\n",
        "y = df[label]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = clf.predict(X_test)\n",
        "report = classification_report(y_test, y_pred, target_names=target_encoder.classes_)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# Save model and encoders\n",
        "os.makedirs(\"risk_model\", exist_ok=True)\n",
        "joblib.dump(clf, \"risk_model/model.pkl\")\n",
        "joblib.dump(encoders, \"risk_model/encoders.pkl\")\n",
        "joblib.dump(target_encoder, \"risk_model/target_encoder.pkl\")\n",
        "\n",
        "print(\"Model training complete. Artifacts saved in 'risk_model' folder.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preprocessing ---\n",
        "# Drop rows with essential missing values\n",
        "df = df.dropna(subset=[\n",
        "    'INJURIES_FATAL', 'INJURIES_TOTAL', 'DAMAGE',\n",
        "    'WEATHER_CONDITION', 'ROADWAY_SURFACE_COND',\n",
        "    'LIGHTING_CONDITION', 'POSTED_SPEED_LIMIT'\n",
        "])\n",
        "\n",
        "# Clean DAMAGE column into a numeric format\n",
        "def parse_damage(val):\n",
        "    if 'OVER' in val:\n",
        "        return 2000\n",
        "    elif 'LESS' in val:\n",
        "        return 500\n",
        "    elif '-' in val:\n",
        "        return sum(map(int, val.replace('$', '').split(' - '))) / 2\n",
        "    else:\n",
        "        return 1000\n",
        "\n",
        "df['DAMAGE_VALUE'] = df['DAMAGE'].apply(parse_damage)\n",
        "\n",
        "# Create risk level label\n",
        "def label_risk(row):\n",
        "    if row['INJURIES_FATAL'] > 0:\n",
        "        return 'High'\n",
        "    elif row['INJURIES_TOTAL'] > 0 or row['DAMAGE_VALUE'] >= 1500:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "df['RISK_LEVEL'] = df.apply(label_risk, axis=1)\n",
        "\n",
        "# --- Feature selection ---\n",
        "features = ['WEATHER_CONDITION', 'LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND',\n",
        "            'POSTED_SPEED_LIMIT', 'DAMAGE_VALUE']\n",
        "df = df[features + ['RISK_LEVEL']]\n",
        "\n",
        "# --- Encode categorical variables ---\n",
        "encoders = {}\n",
        "for col in ['WEATHER_CONDITION', 'LIGHTING_CONDITION', 'ROADWAY_SURFACE_COND']:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "\n",
        "# Encode target\n",
        "target_encoder = LabelEncoder()\n",
        "df['RISK_LEVEL'] = target_encoder.fit_transform(df['RISK_LEVEL'])\n",
        "\n",
        "# --- Train the model ---\n",
        "X = df[features]\n",
        "y = df['RISK_LEVEL']\n",
        "\n",
        "clf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# --- Save model and encoders ---\n",
        "joblib.dump(clf, 'model.pkl')\n",
        "joblib.dump(encoders, 'encoder.pkl')\n",
        "joblib.dump(target_encoder, 'target_encoder.pkl')\n",
        "\n",
        "print(\"âœ… Model and encoders saved successfully.\")"
      ],
      "metadata": {
        "id": "JOvyYDzfhb7M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}